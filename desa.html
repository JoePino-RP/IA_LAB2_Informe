<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Desarrollo de la práctica</title>
        <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.1.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body>
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-light" id="mainNav">
            <div class="container px-4 px-lg-5">
                <a class="navbar-brand" href="index.html">MEC LAB 1</a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    Menu
                    <i class="fas fa-bars"></i>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ms-auto py-4 py-lg-0">
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="index.html">Home</a></li>
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="teor.html">Teoria</a></li>
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="desa.html">Desarrollo de la práctica</a></li>
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="car.html">Carro</a></li>
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="conc.html">Conclusiones</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Page Header-->
        <header class="masthead" style="background-image: url('assets/img/im_rec.jpg')">
            <div class="container position-relative px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        <div class="post-heading">
                            <h1>Desarrollo de la práctica</h1>
                            
                            
                        </div>
                    </div>
                </div>
            </div>
        </header>
        <!-- Post Content-->
        <article class="mb-4">
            <div class="container px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        
                        <h2 class="section-heading">Descripción general de la práctica</h2>
                        
                            El método utilizado para la función de perdida es la ecuación de error cuadrático
                            
                            <a href="#!"><img class="img-fluid" src="assets/img/ecm.png" alt="..." /></a>
                            <span class="caption text-muted">Función de perdida: Ecuación error cuadrático medio</span>
                        
                            <h2 class="section-heading">Algoritmo de reconocimiento de patrones</h2>
                        
                        <p>                            
                            Para la primera entrega se entreno una red neuronal con una tecnologia a elección y un dataset 
                            (de 10 diferentes caracteres) a elección. La tecnologia seleccionada fue el lenguaje de Python, debido a la 
                            facilidad de implementación de redes neuronales mediante paquetes como ScikitLearn, Tensorflow o PyTorch. 
                            Se uso la libreria de Tensorflow y se implemento la red neuronal mediante su API de Keras. El dataset usado 
                            fue el MNIST, una base de datos de 10 numeros escritos a manos, digitos del 0 al 9. Este dataset ya 
                            viene implementado directamente en la API de Keras, cuenta con 70.000 imagenes, usando 60.000 para 
                            Train y 10.000 para Test, despues, se uso el 20% de los datos de Train como validation. Se carga el 
                            dataset mediante:
                        </p>

                        <a href="#!"><img class="img-fluid" src="assets/img/carbon (6).png" alt="..." /></a>
                        <span class="caption text-muted"></span>
                    
                        <p>
                            Este dataset automaticamente nos arroja la división anteriormente descrita, entre datos de entrenamiento 
                            y prueba; una vez realizado esto, se normaliza el dataset, como viene en imagenes .jpg y en escala de 
                            grises, se divide la cantidad de pixeles entre 255, esto se hace como buena practica antes de entrenar 
                            la red. Los labels o 
                            etiquetas, que son los identificadores de cada clase de salida, pasan por un proceso de conversión a 
                            variables dummy, denominado <b>One-hot Encoding</b>. Este proceso permite separar las categorias de los 
                            números en columnas independientes, esto evita que el algoritmo pueda generar mas preferencia sobre 
                            las clases con un mayor número, tambien se considera una buena practica sobre variables categoricas 
                            ordinales , antes de entrar al entrenamiento del algoritmo. El one-hot encoding reduce el overfitting y 
                            permite una ejecución mas rapida del entrenamiento del algoritmo, pues se facilita la operación de 
                            matrices solo con variables binarias (1 y 0). Para evitar problemas en la inversión de matrices (durante 
                            el entrenamiento) debido a la diagonal de unos que representa el proceso de one-hot encoding, se elimina 
                            la primera o ultima columna generada. Esto no supone un problema, pues el digito (columna) que se suprima,
                            quedara descrito mediante la ausencia del dato en las columnas de los otros digitos. Los datos de entrada 
                            del MNIST entran como una imagen de 28x28x1, escala de grises y sin ninguna operación adicional previa al 
                            entrenamiento (como lo puede ser data agumentation). Se describe el modelo de redes convolucionales 
                            (ideales para obtener caracteristicas de imagenes) como se ve a continuación:
                        </p>

                        <a href="#!"><img class="img-fluid" src="assets/img/carbon (3).png" alt="..." /></a>
                        <span class="caption text-muted">Código de modelo de red convolucional</span>

                        <p>
                            El modelo esta descrito mediante la tensorflow como:
                        </p>

                        <a href="#!"><img class="img-fluid" src="assets/img/tab_pin_1.png" alt="..." /></a>
                        <span class="caption text-muted">Modelo de Tensorflow</span>

                        <p>
                            Se eligio el batch de 32, pues se encontro que es lo recomendado en la literatura. Las epocas se 
                            fijaron a 15 pues tras varias pruebas no se encontro mejoria significativa al incrementar este parametro.
                            La función de perdida de definio como “categorical_crossentropy” debido a que es un problema de 
                            clasificación multiclase. Se utilizo un optimizar Adam con los parametros por defecto de Keras.
                            La metrica a evaluar fue el <b>Accuracy</b>. En la ultima epoca, finalizado el entrenamiento se obtuvo:
                        </p>

                        <a href="#!"><img class="img-fluid" src="assets/img/carbon (4).png" alt="..." /></a>
                        <span class="caption text-muted">Código de modelo de red convolucional</span>

                        <p>
                            Se generó una grafica de el error (loss) para cada epoca durante el entrenamiento:
                        </p>

                        <a href="#!"><img class="img-fluid" src="assets/img/gr_pin1.png" alt="..." /></a>
                        <span class="caption text-muted">Gráfica de val loss</span>

                        <p>
                            Se genero otra grafica para mirar el desempeño entre el set de Train y el de Validation, como se puede observar, 
                            en la ultima epoca el valor de la metrica evaluada es muy cercano, dando un modelo muy robusto en cuando a overfitting.
                        </p>

                        <a href="#!"><img class="img-fluid" src="assets/img/gr_pin2.png" alt="..." /></a>
                        <span class="caption text-muted">Gráfica de validación de entrenamiento</span>

                        <p>
                            Evaluando el modelo con los datos de Test, se obtuvo (ver salida), lo que comparado con la grafica anterior, nos indica 
                            un modelo con excelente desempeño tanto con datos de entrenamiento como de test:
                        </p>

                        <a href="#!"><img class="img-fluid" src="assets/img/carbon (5).png" alt="..." /></a>
                        <span class="caption text-muted">Datos de test loss y test accuracy</span>

                        <a href="#!"><img class="img-fluid" src="assets/img/Alg_Rec.jpeg" alt="..." /></a>
                        <span class="caption text-muted">Algoritmo de reconoc de patrones</span>

                        <h2 class="section-heading">Interfaz de usuario</h2>

                        <p>
                            La interfaz de usuario se realiza con Python con la librería tkinter, se tienen dos paneles
                            (uno a la derecha y otro a la izquierda); en el de la derecha se tienen los valores de patrones
                            seguidos por sus porcentajes de coincidencia. En el panel izquierdo se dibuja el patron que se va+
                            a evaluar; haciendo click pinta de blanco y finalmente se evalua con las pestañas superiores
                            ya sea con los valores calculados de forma manual o con keras auto tuner
                        </p>

                        <a href="#!"><img class="img-fluid" src="assets/img/GUI1.PNG" alt="..." /></a>
                        <span class="caption text-muted">GUI con valores generados por Keras</span>
                        
                        <a href="#!"><img class="img-fluid" src="assets/img/GUI_M.PNG" alt="..." /></a>
                        <span class="caption text-muted">GUI con los valores hallados de forma manual</span>
                        


                        <h2 class="section-heading">Generación de trayectorias</h2>

                        <p>
                            Para la segunda entrega se planteo la creación de una red neuronal desde cero, las estrategias usadas 
                            se describiran a continuación, pero la matematica implicita se describira de manera breve (como el 
                            algoritmo de backpropagation). Se carga de la misma manera el dataset desde Keras (como en la primera 
                            entrega), y su uso sera unicamente para el ingreso de datos, mas no para el entrenamiento de la red.
                            Se procede a realizar el proceso de normalización (descrito anterior mente) y de reshape, este ultimo 
                            permite que las imagenes queden en un tensor de 28x28, donde cada casilla contiene el valor normalizado 
                            del pixel en escala de grises. Por último, se usa la utilidad “to_categorical” de Keras para poder obtener 
                            de manera automatica el <b>one hot-encoding</b> de la salida. Se usaron las función de activación 
                            ReLU (para las capas internas) y Softmax (de salida), de manera similar a la implementación de la primera 
                            entrega. La función de perdida, a diferencia del anterior entrega, se utilizo el error cuadratico medio, 
                            por facilidad de implementación en código. El learning rate se definio a 0.001, se uso vectorización 
                            como estrategia para reducir el costo computacional, permitiendo entrenaran con el mismo dataset de MNIST 
                            y en la misma magnitud (60.000 imagenes). Por lo que la entrada del algoritmo era una matriz de 60.000x784, 
                            en donde el 784 pertenece a la cantidad de neuronas en la capa de entrada (28x28, una neurona por pixel). 
                            Los pesos, los parametros <b><i>b</i></b> y los cambios de estos dos, se guardaron en un diccionario a 
                            medida que la red entrenaba, por lo que todo el resultado del entrenamiento quedo en una solo estructura.
                            La arquitectura elegida fueron 4 capas de neuronas, en donde se incluian:
                        </p>

                        <p>
                            <ol> La de entrada, con 784 neuronas.</ol>
                            <br>
                            <ol> Dos capas ocultas, una de 128 y otra de 64 neuronas.</ol>
                            <br>
                            <ol>La última capa de 10 neuronas. </ol>
                            <br>
                            <ol>Se usaron mas neuronas (a comparación de la anterior entrega) para intentar suplir la falta de operaciones 
                            de Pooling o Dropout que teniamos en el anterior modelo.</ol>
                            <br>
                            <ol>Este algoritmo no usa set de validación, solo entrena con las 60.000 para train.</ol>
                            <br>
                            <ol>Tuvo una <b>Accuracy</b> sobre test del 96%.</ol>
                            <br>
                            <ol>El diccionario generado, con todos los pesos del entrenamiento, fue exportado a un archivo .json 
                            para su posterior uso, generando la misma estrategia que la entrega pasada, solo que esta vez solo 
                            se podia exportal los pesos en vez de todo el modelo, ademas de que toca implementar el algoritmo
                             nuevamente si se requiere usar los pesos, pero esto nos entrega la facilidad de no tener que 
                             reentrenar el modelo para usarlo.</ol>
                        </p>

                        <h3 class="subsection-heading">Simulación</h2>

                            <p>
                                Después de haber identificado los números, se procede a realizar la identificación de la trayectoria, 
                                es importante aclarar que la identificación de dicha trayectoria por la red de kohonen no hacia parte 
                                para esta entrega de laboratorio aun así se implementó. Para poder realizarla se lee un archivo CSV 
                                proporcionado por el software Python; esto con el fin de realizar una “conexión” esto entre comillas 
                                porque es la forma en como obtenemos los datos generados de un software y utilizados por el otro, esto 
                                saber las posiciones donde se encuentran los cubos que serán recogidos por el robot realizado. Esta parte 
                                se muestra en la siguiente imagen 
                            </p>
                            <a href="#!"><img class="img-fluid" src="assets/img/Simu_1.jpeg" alt="..." /></a>
                            <span class="caption text-muted">Ecuación error cuadrático medio</span>
                        
                            <p>
                                Posteriormente se realizan las cuatro fases necesarias para este tipo de redes como lo son sus etapas: 
                                Asignación de pesos, Proceso competitivo, proceso cooperativo y adaptativo. Inicialmente se determina cuales 
                                son los valores máximo y mínimo para cada una de sus entradas en este caso para la posición en x y en y, esto 
                                con el fin de generar los pesos con valores aleatorios dentro del rango de los valores de entrada. 
                                Posteriormente se realiza el proceso competitivo el cual consiste en buscar cual neurona está más cerca del 
                                valor de la entrada, esto realizo con la distancia euclidiana con la ecuación que se muestra a continuación 
                            </p>
                            
                            <a href="#!"><img class="img-fluid" src="assets/img/eq_par.png" alt="..." /></a>
                            <span class="caption text-muted"></span>

                            <p>
                                El siguiente paso es el cooperativo este consiste en crear una función gaussiana a partir de la neurona 
                                ganadora del paso anterior y con esto empezar a disminuir el porcentaje de pertenencia en las neuronas 
                                vecinas para este paso se utiliza la siguiente expresión 
                            </p>

                            <a href="#!"><img class="img-fluid" src="assets/img/eq_par2.png" alt="..." /></a>
                            <span class="caption text-muted"></span>

                            <p>
                                Donde el valor de sigma es el número de neuronas y d es el paso que se va generando entre las neuronas 
                                vecinas iniciando en un valor de cero para la neurona ganadora y vas incrementando hacia las dos vecindades de 
                                esta neurona ya que es de una sola dimensión hasta llegar a la neurona más leja.
                            </p>

                            <p>
                                Finalmente se entra a la etapa del proceso adaptativo en el cual se busca que los pesos varíen dependiendo de cual de los 
                                puntos ingresados este mas cercano esto con el fin de crear grupos y poder tener con objetivo la trayectoria mas adecuada 
                                y mas optima para el desplazamiento del robot móvil, para este proceso se utiliza la siguiente expresión 
                            </p>
                            
                            <a href="#!"><img class="img-fluid" src="assets/img/eq_par3.png" alt="..." /></a>
                            <span class="caption text-muted"></span>

                            <p>
                                Es importante aclarar que el valor de μ es un factor de aprendizaje se calcula de la siguiente manera 
                            </p>

                            <a href="#!"><img class="img-fluid" src="assets/img/eq_par4.png" alt="..." /></a>
                            <span class="caption text-muted"></span>
                            
                            <p>
                                donde μ_0 es una constante que por recomendaciones toma el valor 0.1. Ya con esto se termina terminan las cuatro 
                                etapas de esta red y para lograr un resultado optimo se realiza varias veces el cálculo y se para por iteraciones 
                                dando como resultado la siguiente imagen 
                            </p>

                            <a href="#!"><img class="img-fluid" src="assets/img/Simu_2.jpeg" alt="..." /></a>
                            <span class="caption text-muted">Simulación de la trayectorio</span>

                            <p>
                                Como ultimo paso se realiza la limpieza de las neuronas que se encuentran lejas a los puntos esto con el fin de reducir 
                                los puntos intermedios entre las posiciones importante en este caso la ubicación de las cajas como se muestra a continuación. 
                            </p>

                            <a href="#!"><img class="img-fluid" src="assets/img/Simu_3.jpeg" alt="..." /></a>
                            <span class="caption text-muted">Simulación de la trayectorio</span>

                            <p>
                                Para la realización de la simulación se envían las posiciones al Workspace de Matlab esto con el fin de poderlas leer desde 
                                simulink y realizar el control de alto nivel y de bajo nivel como se había mostrado en las entregas anteriores.
                            </p>

                            <iframe width="840" height="473" src="https://www.youtube.com/embed/2bNgyv2GRd8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; 
                            clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

                            <p>
                                En esta nueva entrega, se mejora la red de kohonen mediante TSP este es uno de
                                los problemas de optimización combinatoria más populares
                                donde se describe a un vendedor que debe viajar entre un
                                número N de ciudades.Este problema implica optimizar la
                                duración del recorrido, por lo que el recorrido con la longitud
                                mínimo se considera el recorrido óptimo; se han propuesto
                                varios enfoques para resolver el TSP, algunos de los métodos
                                incluyen el uso de algoritmos evolutivos como el algoritmo
                                genético (GA) o la red neuronal de Kohonen. El TSP es una tarea de optimización que surge en muchas
                                situaciones prácticas, siendo n el número de ciudades y dij es
                                la distancia entre la ciudad i y ciudad j, i, i ∈ 1, 2, 3, ..., n. El
                                TSP encuentra el camino más corto que une todas las ciudades
                                de modo que todas las ciudades se visiten exactamente una
                                vez
                                
                            </p>

                            <a href="#!"><img class="img-fluid" src="assets/img/lab_3_tabla.PNG" alt="..." /></a>
                            <span class="caption text-muted">Visualización interfaz</span>

                            <a href="#!"><img class="img-fluid" src="assets/img/lab_3_2.PNG" alt="..." /></a>
                            <span class="caption text-muted">distribución de los cubos</span>
                            
                            <a href="#!"><img class="img-fluid" src="assets/img/lab_3_1.PNG" alt="..." /></a>
                            <span class="caption text-muted">Mapeo en matlab</span>

                            <a href="#!"><img class="img-fluid" src="assets/img/lab_3_tray.PNG" alt="..." /></a>
                            <span class="caption text-muted">Generación de trayectorias</span>

                            <a href="#!"><img class="img-fluid" src="assets/img/lab_3_tray_limpia.PNG" alt="..." /></a>
                            <span class="caption text-muted">distribución de los cubos</span>
                        <h3 class="subsection-heading">Treayectoria limpia</h2>

                            <p>
                                La red de hopfield tiene la
                                característica de tener un tipo de aprendizaje no supervisado
                                esto quiere decir que un experto al que llamaremos así es
                                diseñador de la arquitectura este le enseña a la red muchos
                                patrones como se hacia con las redes neuronales de entregas
                                pasadas en vez de esto solamente sera un patrón por cada
                                numero del 0 a 9 como se venia trabajando en entregas
                                pasadas.Para explicar de manera sencilla el funcionamiento
                                de esta red representada como una superficie de la red en
                                donde están separados cada uno de los números que se desean
                                identificar, lo deseado es que la red llegue a un estado mínimo
                                de energía es decir que alguno de los patrones ingresados por
                                el usuario encuentre algunas de estos números convergiendo
                                alguno de ellos.Para lograr lo anteriormente mencionado es
                                necesario saber que el cambio de actualización no serán los
                                pesos si no las salidas de la red. 
                            </p>

                            <p>
                                Para probar el funcionamiento
                                de la red se realizaron diversas iteraciones para
                                encontrar los mejores resultados con ambos métodos de entrenamiento
                                y métodos de reconstrucción mediante dos iteraciones realizadas la primera tiene la reconstrucci
                                ón del numero seis el entrenamiento fue echo por pseudo
                                inversa con 24% de ruido el método de reconstrucción usado
                                fue síncrono, caso contrario con el numero 8 a identificar y
                                reconstruido el entrenamiento es realizado con hebbiano y la
                                reconstrucción con el método asíncrono el porcentaje de ruido
                                es del 37%
                            </p>

                        <h3 class="subsection-heading">Algoritmos genéticos</h2>

                            <p>
                                La red de hopfield tiene la
                                característica de tener un tipo de aprendizaje no supervisado
                                esto quiere decir que un experto al que llamaremos así es
                                diseñador de la arquitectura este le enseña a la red muchos
                                patrones como se hacia con las redes neuronales de entregas
                                pasadas en vez de esto solamente sera un patrón por cada
                                numero del 0 a 9 como se venia trabajando en entregas
                                pasadas.Para explicar de manera sencilla el funcionamiento
                                de esta red representada como una superficie de la red en
                                donde están separados cada uno de los números que se desean
                                identificar, lo deseado es que la red llegue a un estado mínimo
                                de energía es decir que alguno de los patrones ingresados por
                                el usuario encuentre algunas de estos números convergiendo
                                alguno de ellos.Para lograr lo anteriormente mencionado es
                                necesario saber que el cambio de actualización no serán los
                                pesos si no las salidas de la red. 
                            </p>
                        <h3 class="subsection-heading">Físico</h2>
                        
                            <p>
                                En la ultima entrega se hizo uso de tecnicas de visión de maquina para poder identificar los caracteres impresos 
                                sobre cubos de 5x5cm, que serian posteriormente recolectados por el robot movil. La estrategia usada se describe a 
                                continuación:
                            </p>

                            <p>
                                <ol>
                                    Primero se genero el terreno y los cubos, el terreno esta en alto contraste con los cubos, 
                                    para que sea de facil identificación. El piso (2x2m) es de color blanco, mientras que los 
                                    cubos son de color negro y blanco, con caracteres impresos directamente del dataset MNIST.
                                </ol>
                                <ol>
                                    Para los numeros, se decidio usar el 1, 4 y 8, por la alta diferencia entre sus trazos que 
                                    permite una mayor precisión al momento de usar la red neuronal.
                                </ol>
                                <ol>
                                    El modelo usado fue el descrito en la primera entrega, pues tuvo mejor desempeño en el dataset de Test, 
                                    asi como en posteriores pruebas en los caracteres dibujados en la interfaz de la segunda entrega.
                                </ol>
                            </p>

                            <p>
                                Se tomaron varias imagenes como la descrita a continuación:
                            </p>

                            <a href="#!"><img class="img-fluid" src="assets/img/piso_1.png" alt="..." /></a>
                            <span class="caption text-muted">Escaneo del tapete y cubos</span>

                            <p>
                                El robot de posicióna cerca del punto (0,0) del m, se generó una mascara sobre la imagen 
                                para despues poder separar los digitos independientemente, en esta mascara se usaron dos 
                                operación morfologicas: un threshold para separar el blanco y negro (binario invertido y OTSU), 
                                y una operación de dilatación (para discriminar los digitos del recuadro que los contiene). La
                                mascara quedo como la imagen que se ve a continuación:
                            </p>

                            <a href="#!"><img class="img-fluid" src="assets/img/mask.png" alt="..." /></a>
                            <span class="caption text-muted">Máscara final</span>
                            
                        
                            
                        </p>
                        <h3 class="subsection-heading">Simulación</h2>
                            <p>
                                A continuación se muestran las simulaciones
                            </p>

                            <p>
                                <ol>
                                    <b>Redes de Kohonen</b>
                                    <iframe width="560" height="315" src="https://www.youtube.com/embed/Vv4yscf0S04" title="YouTube video player" frameborder="0" 
                                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                                </ol>
                                <ol>
                                    <b>Redes de Hopfield</b>
                                    <iframe width="560" height="315" src="https://www.youtube.com/embed/VS6a3wUW6rE" title="YouTube video player" 
                                    frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                                </ol>
                                <ol>
                                    <b>Algoritmos genéticos</b>
                                    <iframe width="560" height="315" src="https://www.youtube.com/embed/KUgDQCGR8nA" title="YouTube video player" frameborder="0" 
                                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                                </ol>
                            </p>
                    </div>
                </div>
            </div>
        </article>
        <!-- Footer-->
        <footer class="border-top">
            <div class="container px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        <ul class="list-inline text-center">
                            <li class="list-inline-item">
                                <a href="#!">
                                    <span class="fa-stack fa-lg">   
                                        <i class="fas fa-circle fa-stack-2x"></i>
                                        <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            <li class="list-inline-item">
                                <a href="#!">
                                    <span class="fa-stack fa-lg">
                                        <i class="fas fa-circle fa-stack-2x"></i>
                                        <i class="fab fa-facebook-f fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            <li class="list-inline-item">
                                <a href="#!">
                                    <span class="fa-stack fa-lg">
                                        <i class="fas fa-circle fa-stack-2x"></i>
                                        <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                        </ul>
                        <div class="small text-center text-muted fst-italic">Copyright &copy; Your Website 2022</div>
                    </div>
                </div>
            </div>
        </footer>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
